# Algorithmes de tri [niveau avancÃ©]

Nous venons de voir que pour rechercher de maniÃ¨re efficace, les donnÃ©es doivent Ãªtre triÃ©es. Mais&nbsp;quelle&nbsp;est la&nbsp;complexitÃ© de l'algorithme du Tri&nbsp;par&nbsp;sÃ©lection vu dans le chapitre <a href="../algo1/cours/2_trie_cherche_trouve/eleve.html#tri-selection">Trie, cherche et trouve</a>â€¯? C'est sa complexitÃ© qui nous donnera une indication sur sa rapiditÃ©.

## Tri&nbsp;par&nbsp;sÃ©lection

Pour rappel, l'{glo}`algo|algorithme` du <a href="../algo1/cours/2_trie_cherche_trouve/eleve.html#tri-selection">**<span style="color:rgb(89, 51, 209)">Tri&nbsp;par&nbsp;sÃ©lection</span>**</a> parcourt le tableau Ã  la recherche des plus petits Ã©lÃ©ments. Afin de trouver le plus petit Ã©lÃ©ment du tableau, il faut commencer par parcourir tous les Ã©lÃ©ments du tableau. Cette opÃ©ration prend $cn$&nbsp;{glo}`instruction|instructions` :&nbsp;$c$&nbsp;instructions pour lâ€™accÃ¨s et la comparaison des Ã©lÃ©ments du tableau, multipliÃ© par le nombre dâ€™Ã©lÃ©ments&nbsp;$n$. Il faut ensuite trouver le plus petit Ã©lÃ©ment des Ã©lÃ©ments restants&nbsp;$n-1$, et ainsi de suite. ConcrÃ¨tement, on va parcourir jusqu'Ã  $n$ Ã©lÃ©ments, $n$&nbsp;fois (pour chacun des Ã©lÃ©ments). La complexitÃ© du Tri&nbsp;par&nbsp;sÃ©lection est donc proportionnelle Ã  $n * n$&nbsp;($n^{2}$), on parle de complexitÃ©&nbsp;**<span style="color:rgb(89, 51, 209)">quadratique</span>**. 

``````{htmlonly} 

`````{togofurther} Calcul de complexitÃ©

````{dropdown} <span style="color:grey">Si vous souhaitez connaÃ®tre les dÃ©tails du calcul de complexitÃ©, cliquez pour lire ce qui suit.</span>
:animate: fade-in-slide-down

Pour calculer la somme totale d'instructions nÃ©cessaires, il faut additionner les termes qui permettent de retrouver le plus petit Ã©lÃ©ment. La premiÃ¨re fois que l'on recherche le plus petit Ã©lÃ©ment il faut parcourir $n$&nbsp;Ã©lÃ©ments. La deuxiÃ¨me fois, il reste Ã  parcourir $n-1$&nbsp;Ã©lÃ©ments. La&nbsp;troisiÃ¨me fois, il faut parcourir les&nbsp;$n-2$&nbsp;Ã©lÃ©ments restants. Et ainsi de suite, jusqu'Ã  ce qu'il ne reste plus qu'un Ã©lÃ©ment. 

Par exemple, si le tableau contient les Ã©lÃ©ments&nbsp;`[5,â€¯2,â€¯3,â€¯6,â€¯1,â€¯4]`, pour trouver le plus petit Ã©lÃ©ment&nbsp;$1$ Ã  la premiÃ¨re itÃ©ration on doit parcourir tout le tableau, ou $6$&nbsp;Ã©lÃ©ments. A la deuxiÃ¨me itÃ©ration, on met l'Ã©lÃ©ment&nbsp;$1$ de cÃ´tÃ© et on parcourt le tableau&nbsp;`[5,â€¯2,â€¯3,â€¯6,â€¯4]`, ce qui fait $5$&nbsp;Ã©lÃ©ments. On met le plus petit Ã©lÃ©ment&nbsp;$2$ de cÃ´tÃ© et dans la troisiÃ¨me itÃ©ration on parcourt le tableau&nbsp;`[5,â€¯3,â€¯4,â€¯6]`, ce qui fait $4$&nbsp;Ã©lÃ©ments. On met&nbsp;$3$ de cÃ´tÃ© et on parcourt encore le tableau `[5,â€¯4,â€¯6]`, ce qui fait $3$&nbsp;Ã©lÃ©ments. Finalement on se retrouve avec les tableaux `[5,â€¯6]` Ã  $2$&nbsp;Ã©lÃ©ments et&nbsp;`[5]` Ã  $1$&nbsp;Ã©lÃ©ment. La somme totale d'Ã©lÃ©ments parcourus est $6â€¯+â€¯5â€¯+â€¯4â€¯+â€¯3â€¯+â€¯2â€¯+â€¯1â€¯=â€¯21$. 

Si on gÃ©nÃ©ralise on obtient :

&nbsp;&nbsp;&nbsp;&nbsp; $n + (n-1) + (n-2) + ... + (n/2 + 1) + n/2 + ... + 3 + 2 + 1$

En rÃ©arrangeant les termes deux par deux de l'extÃ©rieur vers l'intÃ©rieur on obtient plusieurs fois le mÃªme terme :

&nbsp;&nbsp;&nbsp;&nbsp; $(n + 1) + ((n-1) + 2) + ((n-2) + 3) + .... + ((n/2 + 1) + n/2)$

&nbsp;&nbsp;&nbsp;&nbsp; $(n + 1) + (n + 1) + (n + 1) + .... + (n + 1) =$

&nbsp;&nbsp;&nbsp;&nbsp; $(n + 1) * n/2 =$

&nbsp;&nbsp;&nbsp;&nbsp; $n * n/2 + n/2 =$

&nbsp;&nbsp;&nbsp;&nbsp; $n^{2}/2 + n/2$

Si on reprend l'exemple ci&#8209;dessus, on aurait :

&nbsp;&nbsp;&nbsp;&nbsp; $6â€¯+â€¯5â€¯+â€¯4â€¯+â€¯3â€¯+â€¯2â€¯+â€¯1â€¯=$

&nbsp;&nbsp;&nbsp;&nbsp; $(6â€¯+â€¯1)â€¯+â€¯(5â€¯+â€¯2)â€¯(4â€¯+â€¯3) =$ 

&nbsp;&nbsp;&nbsp;&nbsp; $7â€¯*(6/2)â€¯=â€¯7â€¯*â€¯3 =â€¯21$ &nbsp;&nbsp;&nbsp;&nbsp; ou

&nbsp;&nbsp;&nbsp;&nbsp; $6^{2}/2 + 6/2 = 36/2 + 3 = 18 + 3 = 21$

Le terme dominant dans la somme $n^{2}/2 + n/2$ est $n^{2}/2$, plus n grandit plus $n/2$ est insignifiant par rapport Ã  $n^{2}/2$. Par exemple, pour $n = 1000$, $n^{2}/2$ vaut $500000$, alors que $n/2$ vaut seulement&nbsp;$500$. 

Cette somme nous donne le nombre d'Ã©lÃ©ments parcourus. Mais&nbsp;pour chacun de ces Ã©lÃ©ments, plusieurs instructions sont exÃ©cutÃ©es, comme l'accÃ¨s aux Ã©lÃ©ments et leur comparaison. Ces instructions et le terme qui divise par $2$ peuvent Ãªtre absorbÃ©s dans une {glo}`constante|constante` $c$ qui multiplie le terme quadratique $n^{2}$. En ajoutant une constanteÂ a pour prendre en compte le nombre d'instructions qui ne dÃ©pendent pas de la taille des donnÃ©es (comme les initialisations au dÃ©but de lâ€™algorithme), on obtient l'ordre de grandeur $cn^{2} + a$. L'ordre de grandeur est donc **<span style="color:rgb(89, 51, 209)">quadratique</span>**.

````

`````

``````

Si on compare les complexitÃ©s vues jusqu'ici pour un tableau de $1000$ Ã©lÃ©ments on obtient :

| ComplexitÃ©  |Instructions Ã©lÃ©mentaires pour 1000 Ã©lÃ©ments         | 
| :--------------- |:---------------:| 
| LinÃ©aire  |     1000     |  
| Logarithmique  | 10            |   
| Quadratique  | 1000000          |    

Avec une complexitÃ© quadratique, le Tri&nbsp;par&nbsp;sÃ©lection est un algorithme relativement lent.






```{exercise} ComplexitÃ© du Tri&nbsp;par&nbsp;insertion

Quelle est la complexitÃ© de lâ€™algorithme de <a href="../algo1/cours/2_trie_cherche_trouve/eleve.html#tri-insertion">**<span style="color:rgb(89, 51, 209)">Tri&nbsp;par&nbsp;insertion</span>**</a> ? En dâ€™autres termes, si le tableau contient nÂ Ã©lÃ©ments, combien faut&#8209;il dâ€™instructions pour trier ce tableau ? Pour rappel, le Tri&nbsp;par&nbsp;insertion parcourt le tableau dans l'ordre et pour chaque nouvel Ã©lÃ©ment, l'insÃ¨re Ã  l'emplacement correct des Ã©lÃ©ments dÃ©jÃ  parcourus.

<!--
Est&#8209;ce que la complexitÃ© du Tri&nbsp;par&nbsp;insertion est la mÃªme si les Ã©lÃ©ments du tableau sont dÃ©jÃ  triÃ©s ?
-->

```

`````{htmlonly} 
````{solution} 
```{dropdown} <span style="color:grey">Cliquer ici pour voir la rÃ©ponse</span>
:animate: fade-in-slide-down

Dans le pire cas, lorsque les Ã©lÃ©ments sont dans l'ordre inverse, on doit comparer chacun des $n$&nbsp;Ã©lÃ©ments avec $1$&nbsp;Ã &nbsp;$n$ Ã©lÃ©ments. La complexitÃ© de l'algorithme du Tri&nbsp;par&nbsp;insertion est donc $n * n = n^{2}$ ou&nbsp;**quadratique**. 

<!--
Dans le meilleur cas, lorsque les Ã©lÃ©ments sont dÃ©jÃ  dans le bon ordre, on doit comparer chacun des $n$&nbsp;Ã©lÃ©ments avec $1$&nbsp;Ã©lÃ©ment, l'Ã©lÃ©ment prÃ©cÃ©dent. La complexitÃ© du Tri&nbsp;par&nbsp;insertion est donc $n * 1 = n$ ou **linÃ©aire**. 
-->

```
````
`````

````{latexonly} 


```{solution} 

Dans le pire cas, lorsque les Ã©lÃ©ments sont dans l'ordre inverse, on doit comparer chacun des $n$&nbsp;Ã©lÃ©ments avec $1$&nbsp;Ã &nbsp;$n$ Ã©lÃ©ments. La complexitÃ© de l'algorithme du Tri&nbsp;par&nbsp;insertion est donc $n * n = n^{2}$ ou&nbsp;**quadratique**. 

```
````

`````{latexonly} 

````{togofurther} Calcul de complexitÃ©

Si vous souhaitez connaÃ®tre les dÃ©tails du calcul de complexitÃ©, lisez ce qui suit.

Pour calculer la somme totale d'instructions nÃ©cessaires, il faut additionner les termes qui permettent de retrouver le plus petit Ã©lÃ©ment. La premiÃ¨re fois que l'on recherche le plus petit Ã©lÃ©ment il faut parcourir $n$&nbsp;Ã©lÃ©ments. La deuxiÃ¨me fois, il reste Ã  parcourir $n-1$&nbsp;Ã©lÃ©ments. La&nbsp;troisiÃ¨me fois, il faut parcourir les&nbsp;$n-2$&nbsp;Ã©lÃ©ments restants. Et ainsi de suite, jusqu'Ã  ce qu'il ne reste plus qu'un Ã©lÃ©ment. 

Par exemple, si le tableau contient les Ã©lÃ©ments&nbsp;`[5,â€¯2,â€¯3,â€¯6,â€¯1,â€¯4]`, pour trouver le plus petit Ã©lÃ©ment&nbsp;$1$ Ã  la premiÃ¨re itÃ©ration on doit parcourir tout le tableau, ou $6$&nbsp;Ã©lÃ©ments. A la deuxiÃ¨me itÃ©ration, on met l'Ã©lÃ©ment&nbsp;$1$ de cÃ´tÃ© et on parcourt le tableau&nbsp;`[5,â€¯2,â€¯3,â€¯6,â€¯4]`, ce qui fait $5$&nbsp;Ã©lÃ©ments. On met le plus petit Ã©lÃ©ment&nbsp;$2$ de cÃ´tÃ© et dans la troisiÃ¨me itÃ©ration on parcourt le tableau&nbsp;`[5,â€¯3,â€¯4,â€¯6]`, ce qui fait $4$&nbsp;Ã©lÃ©ments. On met&nbsp;$3$ de cÃ´tÃ© et on parcourt encore le tableau `[5,â€¯4,â€¯6]`, ce qui fait $3$&nbsp;Ã©lÃ©ments. Finalement on se retrouve avec les tableaux `[5,â€¯6]` Ã  $2$&nbsp;Ã©lÃ©ments et&nbsp;`[5]` Ã  $1$&nbsp;Ã©lÃ©ment. La somme totale d'Ã©lÃ©ments parcourus est $6â€¯+â€¯5â€¯+â€¯4â€¯+â€¯3â€¯+â€¯2â€¯+â€¯1â€¯=â€¯21$. 

Si on gÃ©nÃ©ralise on obtient :

&nbsp;&nbsp;&nbsp;&nbsp; $n + (n-1) + (n-2) + ... + (n/2 + 1) + n/2 + ... + 3 + 2 + 1$

En rÃ©arrangeant les termes deux par deux de l'extÃ©rieur vers l'intÃ©rieur on obtient plusieurs fois le mÃªme terme :

&nbsp;&nbsp;&nbsp;&nbsp; $(n + 1) + ((n-1) + 2) + ((n-2) + 3) + .... + ((n/2 + 1) + n/2)$

&nbsp;&nbsp;&nbsp;&nbsp; $(n + 1) + (n + 1) + (n + 1) + .... + (n + 1) =$

&nbsp;&nbsp;&nbsp;&nbsp; $(n + 1) * n/2 =$

&nbsp;&nbsp;&nbsp;&nbsp; $n * n/2 + n/2 =$

&nbsp;&nbsp;&nbsp;&nbsp; $n^{2}/2 + n/2$

Si on reprend l'exemple ci&#8209;dessus, on aurait :

&nbsp;&nbsp;&nbsp;&nbsp; $6â€¯+â€¯5â€¯+â€¯4â€¯+â€¯3â€¯+â€¯2â€¯+â€¯1â€¯=$

&nbsp;&nbsp;&nbsp;&nbsp; $(6â€¯+â€¯1)â€¯+â€¯(5â€¯+â€¯2)â€¯(4â€¯+â€¯3) =$ 

&nbsp;&nbsp;&nbsp;&nbsp; $7â€¯*(6/2)â€¯=â€¯7â€¯*â€¯3 =â€¯21$ &nbsp;&nbsp;&nbsp;&nbsp; ou

&nbsp;&nbsp;&nbsp;&nbsp; $6^{2}/2 + 6/2 = 36/2 + 3 = 18 + 3 = 21$

Le terme dominant dans la somme $n^{2}/2 + n/2$ est $n^{2}/2$, plus n grandit plus $n/2$ est insignifiant par rapport Ã  $n^{2}/2$. Par exemple, pour $n = 1000$, $n^{2}/2$ vaut $500000$, alors que $n/2$ vaut seulement&nbsp;$500$. 

Cette somme nous donne le nombre d'Ã©lÃ©ments parcourus. Mais&nbsp;pour chacun de ces Ã©lÃ©ments, plusieurs instructions sont exÃ©cutÃ©es, comme l'accÃ¨s aux Ã©lÃ©ments et leur comparaison. Ces instructions et le terme qui divise par $2$ peuvent Ãªtre absorbÃ©s dans une {glo}`constante|constante` $c$ qui multiplie le terme quadratique $n^{2}$. En ajoutant une constanteÂ a pour prendre en compte le nombre d'instructions qui ne dÃ©pendent pas de la taille des donnÃ©es (comme les initialisations au dÃ©but de lâ€™algorithme), on obtient l'ordre de grandeur $cn^{2} + a$. L'ordre de grandeur est donc **<span style="color:rgb(89, 51, 209)">quadratique</span>**.

````

`````

```{exercise} ComplexitÃ© du Tri&nbsp;Ã &nbsp;bulles

Quelle est la complexitÃ© de lâ€™algorithme de <a href="../algo1/cours/2_trie_cherche_trouve/eleve.html#tri-bulles">**<span style="color:rgb(89, 51, 209)">Tri&nbsp;Ã &nbsp;bulles</span>**</a> ? En dâ€™autres termes, si le tableau contient nÂ Ã©lÃ©ments, combien faut&#8209;il dâ€™instructions pour trier ce tableau ? Pour rappel, le Tri&nbsp;Ã &nbsp;bulles compare les Ã©lÃ©ments deux par deux en les rÃ©arrangeant dans le bon ordre, afin que l'Ã©lÃ©ment le plus grand remonte vers la fin du tableau tel une bulle d'air dans de l'eau. Cette opÃ©ration est rÃ©pÃ©tÃ©e nÂ fois, pour chaque Ã©lÃ©ment du tableau.

```

`````{htmlonly} 
````{solution} 
```{dropdown} <span style="color:grey">Cliquer ici pour voir la rÃ©ponse</span>
:animate: fade-in-slide-down

Dans le cas du Tri&nbsp;Ã &nbsp;bulles, pour chacun des $n$&nbsp;Ã©lÃ©ments on parcourt jusqu'Ã  $n$&nbsp;Ã©lÃ©ments de la liste, ce qui nous donne une complexitÃ©&nbsp;$n * n = n^{2}$ ou une complexitÃ©&nbsp;quadratique.

```
````
`````
````{latexonly} 

```{solution} 

Dans le cas du Tri&nbsp;Ã &nbsp;bulles, pour chacun des $n$&nbsp;Ã©lÃ©ments on parcourt jusqu'Ã  $n$&nbsp;Ã©lÃ©ments de la liste, ce qui nous donne une complexitÃ©&nbsp;$n * n = n^{2}$ ou une complexitÃ©&nbsp;quadratique.

```
````




## Tri&nbsp;rapide

Les trois {glo}`algo|algorithmes` de tri vus dans le chapitre prÃ©cÃ©dent â€“&nbsp;le&nbsp;Tri&nbsp;par&nbsp;sÃ©lection, le Tri&nbsp;par&nbsp;insertion et le Tri&nbsp;Ã &nbsp;bulles&nbsp;â€“ sont des algorithmes de complexitÃ© quadratique. Si on devait utiliser ces tris dans les systÃ¨mes numÃ©riques en place, on passerait beaucoup de notre temps Ã  attendre. Il existe dâ€™autres algorithmes de tri qui sont bien plus rapides. Nous allons voir un {glo}`algo|algorithme` de tri tellement rapide, quâ€™on lui a donnÃ© le nom **<span style="color:rgb(89, 51, 209)">Tri&nbsp;rapide</span>**.

On commence par prendre un Ã©lÃ©ment du tableau que l'on dÃ©finit comme ***<span style="color:rgb(13, 204, 166)">Ã©lÃ©ment pivot</span>***. Cet Ã©lÃ©ment pivot est en gÃ©nÃ©ral soit le premier ou le dernier Ã©lÃ©ment du tableau, soit lâ€™Ã©lÃ©ment du milieu du tableau ou encore un Ã©lÃ©ment pris au hasard. On compare ensuite tous les autres Ã©lÃ©ments du tableau Ã  cet Ã©lÃ©ment pivot. Tous les Ã©lÃ©ments qui sont plus petits que le pivot seront mis Ã  sa gauche et tous les Ã©lÃ©ments qui sont plus grands que le pivot seront mis Ã  sa droite, tout en conservant leur ordre (voir la deuxiÃ¨me ligne de la figure ci&#8209;dessous). 


<span id="tri-rapide"></span>
```{figure} media/Tri_rapide.png
---
alt: tri&nbsp;rapide
width: 315px
name : fig-tri-rapide
---
**Tri&nbsp;rapide**. Illustration du tri&nbsp;rapide sur les mÃªmes donnÃ©es que celles utilisÃ©es pour illustrer les algorithmes de tri du chapitre prÃ©cÃ©dent. On choisit comme Ã©lÃ©ment pivot le dernier Ã©lÃ©ment des tableaux Ã  trier. Tous les Ã©lÃ©ments qui sont plus petits que le pivot se retrouvent Ã  sa gauche, tous les Ã©lÃ©ments plus grands que le pivot se retrouvent Ã  sa droite. L'ordre est conservÃ©.
```


<!--
```{image} media/Tri_rapide.png
:width: 400px
:height: 300px
```
**Tri&nbsp;rapide**. Illustration du tri&nbsp;rapide sur le mÃªme set de donnÃ©es que celui utilisÃ© pour illustrer les algorithmes de tri vus au chapitre prÃ©cÃ©dent. Lâ€™Ã©lÃ©ment pivot est le dernier Ã©lÃ©ment des tableaux Ã  trier
<br>
-->

AprÃ¨s la rÃ©partition des Ã©lÃ©ments autour de lâ€™Ã©lÃ©ment pivot en fonction de leur taille, on se retrouve avec deux tableaux nonÂ triÃ©s, un sous&#8209;tableau Ã &nbsp;chaque cÃ´tÃ© de lâ€™Ã©lÃ©ment pivot. On rÃ©pÃ¨te les mÃªmes opÃ©rations que pour le tableau initial. Pour chaque sous&#8209;tableau, celui de gauche et celui de droite du pivot, on dÃ©termine un nouvel Ã©lÃ©ment pivot (le dernier Ã©lÃ©ment du sous&#8209;tableau). Pour chaque nouvel Ã©lÃ©ment pivot, on met Ã  gauche les Ã©lÃ©ments du sous&#8209;tableau qui sont plus petits que le pivot et on met Ã  droite les Ã©lÃ©ments du sous&#8209;tableau qui sont plus grands que le pivot. **<span style="color:rgb(89, 51, 209)">On rÃ©pÃ¨te</span>** ces mÃªmes opÃ©rations jusquâ€™Ã  ce quâ€™il ne reste plus que des tableaux Ã  $1$ Ã©lÃ©ment (plus que des pivots). A ce stade, le tableau est triÃ©.

IntÃ©ressons&#8209;nous maintenant Ã  la complexitÃ© de cet algorithme. A chaque Ã©tape (Ã &nbsp;chaque ligne de la figure ci&#8209;dessus), on compare tout au plus $n$â€¯Ã©lÃ©ments avec les Ã©lÃ©ments pivots, ce qui nous fait un multiple de $n$&nbsp;{glo}`instruction|instructions` Ã©lÃ©mentaires. Mais&nbsp;combien dâ€™Ã©tapes faut&#8209;il pour que l'algorithme se termine ? 

Dans le meilleur cas, Ã &nbsp;chaque Ã©tape de l'algorithme, lâ€™espace de recherche est divisÃ© par $2$. Nous avons vu dans le chapitre <a href="../algo2/recherche.html#rech-bin">Recherche binaire</a> que lorsquâ€™on divise lâ€™espace de recherche par deux, on obtient une complexitÃ©&nbsp;logarithmique. Le nombre d'Ã©tapes nÃ©cessaires est donc un multiple de $log(n)$. 

Pour obtenir le nombre total d'instructions Ã©lÃ©mentaires on multiplie le nombre d'instructions par Ã©tape avec le nombre d'Ã©tapes. La complexitÃ© que l'obtient est une fonction de&nbsp;$nlog(n)$, il s'agit d'une complexitÃ© **<span style="color:rgb(89, 51, 209)">linÃ©arithmique</span>**. Un algorithme avec une complexitÃ©&nbsp;linÃ©arithmique est plus lent qu'un algorithme de complexitÃ©&nbsp;linÃ©aire (la recherche&nbsp;linÃ©aire) ou de complexitÃ©&nbsp;logarithmique (la recherche&nbsp;binaire). Par contre, il est bien plus rapide qu'un algorithme de complexitÃ©&nbsp;quadratique (le tri&nbsp;par&nbsp;sÃ©lection). La figure ci&#8209;dessous permet de comparer la vitesse de croissance des complexitÃ©s Ã©tudiÃ©es jusqu'ici. Le tri&nbsp;rapide est donc vraiment l'algorithme de tri le plus  rapide vu jusqu'ici et la complexitÃ© nous permet de comprendre pourquoi c'est le cas.


```{figure} media/graph_comp.png
---
alt: comparaison des complexitÃ©s vues jusqu'ici
width: 500px
name : fig-compl-4
---
**Comparaison de complexitÃ©s**. La vitesse de croissance en fonction de la taille du tableau n est montrÃ©e pour toutes les complexitÃ©s vues jusqu'ici. Plus le nombre dâ€™instructions Ã©lÃ©mentaires est grand en fonction de la taille des donnÃ©es, plus lâ€™algorithme est lent. 
```

La premiÃ¨re question que lâ€™on se pose lorsquâ€™on analyse un algorithme est son ordre de complexitÃ©&nbsp;temporelle. Si lâ€™algorithme est trop lent, il ne sera pas utilisable dans la vie rÃ©elle. Pour le problÃ¨meÂ duÂ Tri, la stratÃ©gie **<span style="color:rgb(89, 51, 209)">Â«Â diviserÂ pourÂ rÃ©gnerÂ Â»</span>** vient Ã  nouveau Ã  la rescousse.






```{exercise} Le pire du Tri&nbsp;rapide

Que se passe-t-il si on essaie de trier un tableau dÃ©jÃ  triÃ© avec l'algorithme du **<span style="color:rgb(89, 51, 209)">Tri&nbsp;rapide</span>**, en prenant toujours comme pivot le dernier Ã©lÃ©mentâ€¯? Essayer par exemple avec le tableau `[1,â€¯2,â€¯3,â€¯4,â€¯5,â€¯6,â€¯7]`. 

Combien d'Ã©tapes sont nÃ©cessaires pour que l'algorithme se termineâ€¯? Quelle est la complexitÃ© dans ce casâ€¯? Est&#8209;ce qu'un autre choix de pivot aurait Ã©tÃ© plus judicieuxâ€¯?

```

`````{htmlonly} 
````{solution} 
```{dropdown} <span style="color:grey">Cliquer ici pour voir la rÃ©ponse</span>
:animate: fade-in-slide-down

Si on simule l'algorithme de Tri&nbsp;rapide pour le tableau `[1,â€¯2,â€¯3,â€¯4,â€¯5,â€¯6,â€¯7]` avec comme pivot le dernier Ã©lÃ©ment on se retrouve avec les sous-tableaux suivants (le pivot est affichÃ© en gras, les Ã©lÃ©ments dÃ©jÃ  triÃ©s sont affichÃ©s en italique)â€¯:

`[1,â€¯2,â€¯3,â€¯4,â€¯5,â€¯6,â€¯**7**]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯3,â€¯4,â€¯5,â€¯**6**]â€¯[*7*]â€¯[]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯3,â€¯4,â€¯**5**]â€¯[*6*]â€¯[]â€¯[*7*]â€¯[]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯3,â€¯**4**]â€¯[*5*]â€¯[]â€¯[*6*]â€¯[]â€¯[*7*]â€¯[]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯**3**]â€¯[*4*][]â€¯[*5*]â€¯[]â€¯[*6*]â€¯[]â€¯[*7*]â€¯[]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯**2**]â€¯[*3*]â€¯[]â€¯[*4*][]â€¯[*5*]â€¯[]â€¯[*6*]â€¯[]â€¯[*7*]â€¯[]`

&nbsp;&nbsp;&nbsp;&nbsp; `[**1**]â€¯[*2*]â€¯[]â€¯[*3*]â€¯[]â€¯[*4*][]â€¯[*5*]â€¯[]â€¯[*6*]â€¯[]â€¯[*7*]â€¯[]`

&nbsp;&nbsp;&nbsp;&nbsp; `[]â€¯[*1*]â€¯[]â€¯[*2*],â€¯[*3*]â€¯[*4*][]â€¯[*5*]â€¯[]â€¯[*6*]â€¯[]â€¯[*7*]â€¯[]`

`[1]â€¯[2]â€¯[3]â€¯[4]â€¯[5]â€¯[6]â€¯[7]`â€¯

Lorsque les Ã©lÃ©ments du tableau sont dÃ©jÃ  triÃ©s, l'espace de recherche n'est plus divisÃ© par deux. On se retrouve avec des sous-tableaux dÃ©sÃ©quilibrÃ©s, vides d'un cÃ´tÃ© et pleins de l'autre. Le nombre d'Ã©tapes n'est donc plus $log(n)$, mais vaut&nbsp;$n$ ($7$&nbsp;Ã©tapes de traitement). Lorsqu'on multiple le nombre d'Ã©tapes (lignes) au nombre d'Ã©lÃ©ments Ã  comparer par ligne, on est plutÃ´t dans une complexitÃ©&nbsp;$n*n$ (ou&nbsp;$n^{2}$), donc quadratique. Dans ce scÃ©nario, le tri&nbsp;rapide n'est donc plus si rapide. Le choix du pivot est alors crucial et dÃ©pend du contenu du tableau.

Si on prend comme pivot l'Ã©lÃ©ment du milieu du tableau, on se retrouve avec des sous-tableaux Ã©quilibrÃ©s, qui contiennent un nombre similaire d'Ã©lÃ©ments. Dans ce cas l'algorithme a besoin de moins d'Ã©tapes pour trouver la solution, de l'ordre de $log(n)$, ici $3$&nbsp;lignes et Ã©quivalent Ã &nbsp;$log_{2}(7)$, de traitement au lieu de&nbsp;$7$ auparavant : 

`[1,â€¯2,â€¯3,â€¯**4**,â€¯5,â€¯6,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯**2**,â€¯3]â€¯[*4*],â€¯[5,â€¯**6**,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[**1**]â€¯[*2*]â€¯[**3**]â€¯[*4*],â€¯[**5**]â€¯[*6*]â€¯[**7**]`

&nbsp;&nbsp;&nbsp;&nbsp; `[]â€¯[*1*]â€¯[]â€¯[*2*]â€¯[]â€¯[*3*]â€¯[]â€¯[*4*]â€¯[]â€¯[*5*]â€¯[]â€¯[*6*]â€¯[]â€¯[*7*]`

`[1]â€¯[2]â€¯[3]â€¯[4]â€¯[5]â€¯[6]â€¯[7]`â€¯

```
````
`````

````{latexonly} 

```{solution} 

Si on simule l'algorithme de Tri&nbsp;rapide pour le tableau `[1,â€¯2,â€¯3,â€¯4,â€¯5,â€¯6,â€¯7]` avec comme pivot le dernier Ã©lÃ©ment on se retrouve avec les sous-tableaux suivants (le pivot est affichÃ© en gras, les Ã©lÃ©ments dÃ©jÃ  triÃ©s sont affichÃ©s en italique)â€¯:

`[1,â€¯2,â€¯3,â€¯4,â€¯5,â€¯6,â€¯**7**]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯3,â€¯4,â€¯5,â€¯**6**]â€¯[*7*]â€¯[]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯3,â€¯4,â€¯**5**]â€¯[*6*]â€¯[]â€¯[*7*]â€¯[]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯3,â€¯**4**]â€¯[*5*]â€¯[]â€¯[*6*]â€¯[]â€¯[*7*]â€¯[]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯**3**]â€¯[*4*][]â€¯[*5*]â€¯[]â€¯[*6*]â€¯[]â€¯[*7*]â€¯[]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯**2**]â€¯[*3*]â€¯[]â€¯[*4*][]â€¯[*5*]â€¯[]â€¯[*6*]â€¯[]â€¯[*7*]â€¯[]`

&nbsp;&nbsp;&nbsp;&nbsp; `[**1**]â€¯[*2*]â€¯[]â€¯[*3*]â€¯[]â€¯[*4*][]â€¯[*5*]â€¯[]â€¯[*6*]â€¯[]â€¯[*7*]â€¯[]`

&nbsp;&nbsp;&nbsp;&nbsp; `[]â€¯[*1*]â€¯[]â€¯[*2*],â€¯[*3*]â€¯[*4*][]â€¯[*5*]â€¯[]â€¯[*6*]â€¯[]â€¯[*7*]â€¯[]`

`[1]â€¯[2]â€¯[3]â€¯[4]â€¯[5]â€¯[6]â€¯[7]`â€¯

Lorsque les Ã©lÃ©ments du tableau sont dÃ©jÃ  triÃ©s, l'espace de recherche n'est plus divisÃ© par deux. On se retrouve avec des sous-tableaux dÃ©sÃ©quilibrÃ©s, vides d'un cÃ´tÃ© et pleins de l'autre. Le nombre d'Ã©tapes n'est donc plus $log(n)$, mais vaut&nbsp;$n$ ($7$&nbsp;Ã©tapes de traitement). Lorsqu'on multiple le nombre d'Ã©tapes (lignes) au nombre d'Ã©lÃ©ments Ã  comparer par ligne, on est plutÃ´t dans une complexitÃ©&nbsp;$n*n$ (ou&nbsp;$n^{2}$), donc quadratique. Dans ce scÃ©nario, le tri&nbsp;rapide n'est donc plus si rapide. Le choix du pivot est alors crucial et dÃ©pend du contenu du tableau.

Si on prend comme pivot l'Ã©lÃ©ment du milieu du tableau, on se retrouve avec des sous-tableaux Ã©quilibrÃ©s, qui contiennent un nombre similaire d'Ã©lÃ©ments. Dans ce cas l'algorithme a besoin de moins d'Ã©tapes pour trouver la solution, de l'ordre de $log(n)$, ici $3$&nbsp;lignes et Ã©quivalent Ã &nbsp;$log_{2}(7)$, de traitement au lieu de&nbsp;$7$ auparavant : 

`[1,â€¯2,â€¯3,â€¯**4**,â€¯5,â€¯6,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯**2**,â€¯3]â€¯[*4*],â€¯[5,â€¯**6**,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[**1**]â€¯[*2*]â€¯[**3**]â€¯[*4*],â€¯[**5**]â€¯[*6*]â€¯[**7**]`

&nbsp;&nbsp;&nbsp;&nbsp; `[]â€¯[*1*]â€¯[]â€¯[*2*]â€¯[]â€¯[*3*]â€¯[]â€¯[*4*]â€¯[]â€¯[*5*]â€¯[]â€¯[*6*]â€¯[]â€¯[*7*]`

`[1]â€¯[2]â€¯[3]â€¯[4]â€¯[5]â€¯[6]â€¯[7]`â€¯

```
````



````{togofurther} 

MÃªme si deux algorithmes de tri ont la mÃªme complexitÃ©&nbsp;temporelle, c'est&#8209;Ã &#8209;dire qu'ils prennent un temps comparable pour trier des donnÃ©es, ils ne prennent pas la mÃªme place en mÃ©moire. Pour un algorithme qui prend peu de place en memoire (par exemple le tri&nbsp;par&nbsp;insertion), on dit qu'il a une plus petite **<span style="color:rgb(89, 51, 209)">Â«Â complexitÃ©Â spatialeÂ Â»</spans>**.

````




Si on trie un tableau qui est en fait dÃ©jÃ  triÃ© avec le tri&nbsp;par&nbsp;insertion, la complexitÃ© dans ce cas est linÃ©aire.  Au contraire, si on trie ce mÃªme tableau avec le tri&nbsp;rapide, la complexitÃ© dans ce cas est quadratique. On voit donc que selon le tableau que lâ€™on trie, le tri&nbsp;rapide peut Ãªtre bien plus lent que le tri&nbsp;par&nbsp;insertion.

Une analyse complÃ¨te dâ€™un algorithme consiste Ã  calculer la complexitÃ© non seulement dans le **<span style="color:rgb(89, 51, 209)">cas moyen</span>**, mais aussi dans le **<span style="color:rgb(89, 51, 209)">meilleur cas</span>** et dans le **<span style="color:rgb(89, 51, 209)">pire cas</span>**. 


````{togofurther}

Une analyse complÃ¨te va Ã©galement calculer les constantes qui influencent lâ€™ordre de complexitÃ©. Ces constantes ne sont pas importantes lors dâ€™une premiÃ¨re analyse dâ€™un algorithme. En&nbsp;effet, les constantes nâ€™ont que peu dâ€™effet pour une grande taille des donnÃ©es $n$, câ€™est uniquement le terme qui grandit le plus rapidement en fonction de $n$ qui compte, et qui figure dans un premier temps dans lâ€™ordre de complexitÃ©. Par contre, lorsque lâ€™on souhaite comparer deux algorithmes de mÃªme complexitÃ©, il faut estimer les constantes et choisir l'algorithme avec une constante plus petite.

La notation Â«Â GrandÂ OÂ Â», que l'on utilise pour Ã©crire mathÃ©matiquement la complexitÃ©, dÃ©signe en fait la complexitÃ© dans le pire cas. Les diffÃ©rentes complexitÃ©s vues jusqu'ici seraient notÃ©es : $O(n)$, $O(log(n))$, $O(n^{2})$ et $O(nlog(n))$. Arrivez&#8209;vous Ã  trouver les adjectifs correspondants ?

````

```{exercise} Le meilleur et le pire du Tri&nbsp;par&nbsp;insertion

Que se passe-t-il si on essaie de trier un tableau dÃ©jÃ  triÃ© avec l'algorithme du **<span style="color:rgb(89, 51, 209)">Tri&nbsp;par&nbsp;insertion</span>**â€¯? Essayer par exemple avec le tableau `[1,â€¯2,â€¯3,â€¯4,â€¯5,â€¯6,â€¯7]`. 

Combien d'Ã©tapes sont nÃ©cessaires pour que l'algorithme se termineâ€¯? Quelle est la complexitÃ© dans ce casâ€¯?

Que se passe-t-il si on essaie de trier un tableau dÃ©jÃ  triÃ©, mais dans l'ordre inverse de celui qui est souhaitÃ©, avec l'algorithme du Tri&nbsp;par&nbsp;insertionâ€¯? Essayer par exemple avec le tableau `[4,â€¯3,â€¯2,â€¯1]`.

```

`````{htmlonly} 
````{solution} 
```{dropdown} <span style="color:grey">Cliquer ici pour voir la rÃ©ponse</span>
:animate: fade-in-slide-down

Si on simule l'algorithme de Tri&nbsp;par&nbsp;insertion pour le tableau `[1,â€¯2,â€¯3,â€¯4,â€¯5,â€¯6,â€¯7]` on se retrouve avec la configuration suivante (l'Ã©lÃ©ment insÃ©rÃ© est affichÃ© en gras, l'Ã©lÃ©ment auquel on le compare en italique)â€¯:

&nbsp;&nbsp;&nbsp;&nbsp; `[**1**,â€¯2,â€¯3,â€¯4,â€¯5,â€¯6,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[*1*]â€¯[**2**,â€¯3,â€¯4,â€¯5,â€¯6,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯*2*]â€¯[**3**,â€¯4,â€¯5,â€¯6,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯*3*]â€¯[**4**,â€¯5,â€¯6,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯3,â€¯*4*]â€¯[**5**,â€¯6,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯3,â€¯4,â€¯*5*]â€¯[**6**,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯3,â€¯4,â€¯5,â€¯*6*]â€¯[**7**]`

`[1,â€¯2,â€¯3,â€¯4,â€¯5,â€¯6,â€¯7]`

On voit qu'il y a besoin de $7$&nbsp;Ã©tapes, ou $n$&nbsp;Ã©tapes, car autant que d'Ã©lÃ©ments dans le tableau. Dans chaque Ã©tape on n'a besoin de comparer qu'une fois, avec l'Ã©lÃ©ment prÃ©cÃ©dent. La complexitÃ© dans ce cas est $n*1 = n$ ou&nbsp;linÃ©aire. Pour des donnÃ©es presque triÃ©es, le Tri&nbsp;par&nbsp;insertion est encore plus rapide que le Tri&nbsp;rapide.

A premier abord, trier le tableau `[5, 4â€¯,3,â€¯2,â€¯1]` avec le Tri&nbsp;par&nbsp;insertion ne prÃ©sente pas de difficultÃ©s. Regardons ce qui se passe :

&nbsp;&nbsp;&nbsp;&nbsp; `[**5**,â€¯4, 3,â€¯2,â€¯1]`

&nbsp;&nbsp;&nbsp;&nbsp; `[*5*]â€¯[**4**,â€¯3,â€¯2,â€¯1]`

&nbsp;&nbsp;&nbsp;&nbsp; `[4,â€¯*5*]â€¯[**3**,â€¯2,â€¯1]`

&nbsp;&nbsp;&nbsp;&nbsp; `[*4*,â€¯**3**,â€¯5]â€¯[2,â€¯1]`

&nbsp;&nbsp;&nbsp;&nbsp; `[3,â€¯4,â€¯*5*]â€¯[**2**,â€¯1]`

&nbsp;&nbsp;&nbsp;&nbsp; `[3,â€¯*4*,â€¯**2**,â€¯5]â€¯[1]`

&nbsp;&nbsp;&nbsp;&nbsp; `[*3*,â€¯**2**,â€¯4,â€¯5]â€¯[1]`

&nbsp;&nbsp;&nbsp;&nbsp; `[2,â€¯3,â€¯4,â€¯*5*]â€¯[**1**]`

&nbsp;&nbsp;&nbsp;&nbsp; `[2,â€¯3,â€¯*4*,â€¯**1**,â€¯5]`

&nbsp;&nbsp;&nbsp;&nbsp; `[2,â€¯*3*,â€¯**1**,â€¯4,â€¯5]`

&nbsp;&nbsp;&nbsp;&nbsp; `[*2*,â€¯**1**,â€¯3,â€¯4,â€¯5]`

`[1,â€¯2,â€¯3,â€¯4,â€¯5]`

Cette fois&#8209;ci on se retrouve dans la pire configuration pour le Tri&nbsp;par&nbsp;insertion, oÃ¹ chaque Ã©lÃ©ment doit Ãªtre comparÃ© Ã &nbsp;chaque autre Ã©lÃ©ment. Ici nous avons besoin de $11$&nbsp;Ã©tapes de traitement pour trier $5$&nbsp;Ã©lÃ©ments, alors qu'avant $7$&nbsp;Ã©tapes suffisaient pour trier $7$&nbsp;Ã©lÃ©ments. Lorsqu'on doit trier un grand nombre d'Ã©lÃ©ments, ces diffÃ©rence est significative et peut rendre un algorithme nonâ€¯utilisable.

```
````
`````

````{latexonly} 

```{solution} 

Si on simule l'algorithme de Tri&nbsp;par&nbsp;insertion pour le tableau `[1,â€¯2,â€¯3,â€¯4,â€¯5,â€¯6,â€¯7]` on se retrouve avec la configuration suivante (l'Ã©lÃ©ment insÃ©rÃ© est affichÃ© en gras, l'Ã©lÃ©ment auquel on le compare en italique)â€¯:

&nbsp;&nbsp;&nbsp;&nbsp; `[**1**,â€¯2,â€¯3,â€¯4,â€¯5,â€¯6,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[*1*]â€¯[**2**,â€¯3,â€¯4,â€¯5,â€¯6,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯*2*]â€¯[**3**,â€¯4,â€¯5,â€¯6,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯*3*]â€¯[**4**,â€¯5,â€¯6,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯3,â€¯*4*]â€¯[**5**,â€¯6,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯3,â€¯4,â€¯*5*]â€¯[**6**,â€¯7]`

&nbsp;&nbsp;&nbsp;&nbsp; `[1,â€¯2,â€¯3,â€¯4,â€¯5,â€¯*6*]â€¯[**7**]`

`[1,â€¯2,â€¯3,â€¯4,â€¯5,â€¯6,â€¯7]`

On voit qu'il y a besoin de $7$&nbsp;Ã©tapes, ou $n$&nbsp;Ã©tapes, car autant que d'Ã©lÃ©ments dans le tableau. Dans chaque Ã©tape on n'a besoin de comparer qu'une fois, avec l'Ã©lÃ©ment prÃ©cÃ©dent. La complexitÃ© dans ce cas est $n*1 = n$ ou&nbsp;linÃ©aire. Pour des donnÃ©es presque triÃ©es, le Tri&nbsp;par&nbsp;insertion est encore plus rapide que le Tri&nbsp;rapide.

A premier abord, trier le tableau `[5, 4â€¯,3,â€¯2,â€¯1]` avec le Tri&nbsp;par&nbsp;insertion ne prÃ©sente pas de difficultÃ©s. Regardons ce qui se passe :

&nbsp;&nbsp;&nbsp;&nbsp; `[**5**,â€¯4, 3,â€¯2,â€¯1]`

&nbsp;&nbsp;&nbsp;&nbsp; `[*5*]â€¯[**4**,â€¯3,â€¯2,â€¯1]`

&nbsp;&nbsp;&nbsp;&nbsp; `[4,â€¯*5*]â€¯[**3**,â€¯2,â€¯1]`

&nbsp;&nbsp;&nbsp;&nbsp; `[*4*,â€¯**3**,â€¯5]â€¯[2,â€¯1]`

&nbsp;&nbsp;&nbsp;&nbsp; `[3,â€¯4,â€¯*5*]â€¯[**2**,â€¯1]`

&nbsp;&nbsp;&nbsp;&nbsp; `[3,â€¯*4*,â€¯**2**,â€¯5]â€¯[1]`

&nbsp;&nbsp;&nbsp;&nbsp; `[*3*,â€¯**2**,â€¯4,â€¯5]â€¯[1]`

&nbsp;&nbsp;&nbsp;&nbsp; `[2,â€¯3,â€¯4,â€¯*5*]â€¯[**1**]`

&nbsp;&nbsp;&nbsp;&nbsp; `[2,â€¯3,â€¯*4*,â€¯**1**,â€¯5]`

&nbsp;&nbsp;&nbsp;&nbsp; `[2,â€¯*3*,â€¯**1**,â€¯4,â€¯5]`

&nbsp;&nbsp;&nbsp;&nbsp; `[*2*,â€¯**1**,â€¯3,â€¯4,â€¯5]`

`[1,â€¯2,â€¯3,â€¯4,â€¯5]`

Cette fois&#8209;ci on se retrouve dans la pire configuration pour le Tri&nbsp;par&nbsp;insertion, oÃ¹ chaque Ã©lÃ©ment doit Ãªtre comparÃ© Ã &nbsp;chaque autre Ã©lÃ©ment. Ici nous avons besoin de $11$&nbsp;Ã©tapes de traitement pour trier $5$&nbsp;Ã©lÃ©ments, alors qu'avant $7$&nbsp;Ã©tapes suffisaient pour trier $7$&nbsp;Ã©lÃ©ments. Lorsqu'on doit trier un grand nombre d'Ã©lÃ©ments, ces diffÃ©rence est significative et peut rendre un algorithme nonâ€¯utilisable.

```
````


## Exercices

```{exercise} Une question Ã  un million

Si une instruction prend $10^{-6}$ secondes, combien de temps faut&#8209;il pour trier un tableau dâ€™un million dâ€™Ã©lÃ©ments avec le tri Ã  sÃ©lection comparÃ© au tri&nbsp;rapide (sans tenir compte de la constante) ?

```

```{exercise} Une question de pivot

Trier le tableau suivant avec lâ€™algorithme de tri&nbsp;rapide : `[3, 6, 8, 7, 1, 9, 4, 2, 5]` Ã  la main, en prenant le dernier Ã©lÃ©ment comme pivot. ReprÃ©senter lâ€™Ã©tat du tableau lors de toutes les Ã©tapes intermÃ©diaires.

Est&#8209;ce que le choix du pivot est important ?

```

```{exercise} Une question de sÃ©lection

Trier le tableau suivant avec lâ€™algorithme de tri&nbsp;par&nbsp;sÃ©lection : `[3, 6, 8, 7, 1, 9, 4, 2, 5]` Ã  la main. ReprÃ©senter lâ€™Ã©tat du tableau lors de toutes les Ã©tapes intermÃ©diaires.

```

```{exercise} Une question d'insertion

Trier le tableau suivant avec lâ€™algorithme de tri&nbsp;par&nbsp;insertion : `[3, 6, 8, 7, 1, 9, 4, 2, 5]` Ã  la main. ReprÃ©senter lâ€™Ã©tat du tableau lors de toutes les Ã©tapes intermÃ©diaires.

```

```{exercise} Une question de bulles

Trier le tableau suivant avec lâ€™algorithme de tri&nbsp;Ã &nbsp;bulles : `[3, 6, 8, 7, 1, 9, 4, 2, 5]` Ã  la main. ReprÃ©senter lâ€™Ã©tat du tableau lors de toutes les Ã©tapes intermÃ©diaires.

```

````{exercise} Une question de chronomÃ¨tre ğŸ”Œ

CrÃ©er une liste qui contient les valeurs de $1$ Ã  $n$ dans un ordre alÃ©atoire, oÃ¹ $n$ prend la valeur $100$. ImplÃ©menter au moins deux des trois algorithmes de tri vu au cours.

A lâ€™aide du module `time` et de sa fonction `time()`, chronomÃ©trer le temps prend le tri d'une liste de $100$, $500$, $1000$, $10000$, $20000$, $30000$, $40000$ puis $50000$ nombres. Noter les temps obtenus et les afficher sous forme de courbe dans un tableur. 

Ce graphique permet de visualiser le temps dâ€™exÃ©cution du tri en fonction de la taille de la liste. Que peut&#8209;on constater ? Sur la base de ces mesures, peut&#8209;on estimer le temps que prendrait le tri de 100000 Ã©lÃ©ments ? Lancer votre programme avec 100000 Ã©lÃ©ments et comparer le temps obtenu avec votre estimation.

````


````{eval}

VÃ©rifiez votre comprÃ©hension :

1. Je sais que grÃ¢ce Ã  la stratÃ©gie algorithmique Â« diviser&nbsp;pour&nbsp;rÃ©gner Â», je ne passe pas mon temps Ã  attendre que lâ€™ordinateur me donne une rÃ©ponse.

2. Je sais comment trier de maniÃ¨re rapide.

3. Je sais que la complexitÃ©&nbsp;temporelle peut changer selon la configuration des donnÃ©es, en plus du cas moyen, il est Ã©galement utile dâ€™estimer le pire et le meilleur cas.

````

