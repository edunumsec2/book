<style>
.button {
  background-color: white;
  border: 1px solid;
  border-color: black;
  font-family:"Lato",sans-serif;
  font-weight:350;
  color: black!important;
  padding: 10px 10px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 16px;
  margin: 4px 2px;
  cursor: pointer;
}
.button:hover {
  text-decoration:none;
  background-color: black; 
  color: white!important;
}
.round-button {
    display:block;
    width:100px;
    height:100px;
    line-height:17px;
    border:0px ;
    border-radius: 50%;
    color:#6069db;
    text-align:center;
    text-decoration:none;
    display: table-cell;
    vertical-align: middle;
    background: #6069db;
    box-shadow: 0 0 0px gray;
    font-size:14px;
    font-weight:bold;
    }

</style>

<div align="right"> 
    <a href="http://files.edunumsec2.ch/enjeux-sociaux/xx.pdf" class="round-button">
         <font color=white id="demo">Voir <br>dossier</font>
    </a>
</div>

# IA et enjeux de l'automatisation

<br>

Ce dossier aborde le vaste sujet que forment lâ€™intelligence artificielle (IA) et lâ€™automatisation. Quâ€™est-ce que lâ€™IA, dâ€™oÃ¹ vient-elle et quelle place occupe-t-elle dans nos vies ? Comment les imaginaires culturels impactent-ils les discours sur lâ€™IA ? Quelles sont les opportunitÃ©s, les craintes et les dÃ©fis propres aux applications de lâ€™IA ? Comment rÃ©guler ces nouvelles technologies ?

## Objectifs

* Comprendre le contexte dâ€™Ã©mergence de lâ€™intelligence artificielle
* ConnaÃ®tre les forces et les faiblesses de lâ€™IA
* Prendre conscience des dÃ©fis de l'automatisation en matiÃ¨re de dÃ©lÃ©gation et de rÃ©gulation


##

La quÃªte dâ€™une forme dâ€™intelligence artificielle nâ€™est pas nouvelle et apparait dans la littÃ©rature dÃ¨s 1818 avec le fameux roman *Frankenstein* de Mary Shelley. Plus tard, la science-fiction en fera Ã©galement un thÃ¨me central et rÃ©current, des premiers robots rebelles de la piÃ¨ce R.U.R. (ÄŒapek, 1920) Ã  la voix artificielle de Her du film homonyme (Spike Jonze, 2013). Ces personnages sont des exemples dâ€™**intelligence artificielle forte**, ils sont autonomes et dotÃ©s dâ€™une conscience. Lâ€™impact des histoires et des images issues de la science-fiction sont perceptibles dans certaines reprÃ©sentations, fantasmes et inquiÃ©tudes suscitÃ©es par lâ€™IA. Mais les rÃ©cits fictifs qui mobilisent diverses formes dâ€™IA nâ€™ont pas la prÃ©tention de prÃ©dire lâ€™avenir. De plus, les techniques actuelles se limitent Ã  de lâ€™**intelligence artificielle faible**, centrÃ©es sur une tÃ¢che prÃ©cise. 

La lecture des rÃ©cits de science-fiction permet surtout dâ€™identifier des problÃ©matiques centrales concernant les aspects philosophiques, sociaux ou juridiques autours de lâ€™IA. Le retour en force de lâ€™IA observÃ© depuis le dÃ©but des annÃ©es 2010 nous amÃ¨ne Ã  rÃ©flÃ©chir Ã  certaines questions longtemps restreintes au monde de la fiction. Quelle place accorde-t-on Ã  lâ€™IA et Ã  ses technologies ? Sont-elles pensÃ©es en opposition ou au contraire, avec lâ€™intelligence humaine ? Qui est responsable en cas de problÃ¨me gÃ©nÃ©rÃ© par une machine ?

Pour apporter des pistes de rÃ©flexion, un rappel du contexte dâ€™Ã©mergence de lâ€™IA est proposÃ© avant de prÃ©senter trois enjeux contemporains propres Ã  ses utilisations.



<div align="left"; style="font-size:20px ;color:rgb(0, 0, 0); font-family:helvetica">
  <b>ğŸ•¶ Une vision de lâ€™intelligence</b>
</div>

<br>

Lâ€™Ã©mergence des premiÃ¨res techniques dites dâ€™intelligence artificielle sâ€™inscrit dans le courant de pensÃ©e de la cybernÃ©tique, fondÃ© par le mathÃ©maticien Norbert Wiener Ã  la fin des annÃ©es 1940 aux Ã‰tats-Unis. Ce mouvement interdisciplinaire considÃ¨re que tous les systÃ¨mes vivants (humains et animaux) et matÃ©riel (machines) sont rÃ©gulÃ©s par une loi gÃ©nÃ©rale basÃ©e sur des boucles de rÃ©troaction ou feedback. Cette conjecture permet de placer les humains et les machines sur un pied dâ€™Ã©galitÃ© quant Ã  leur fonctionnement. Elle promeut une vision formaliste et donc simplificatrice du fonctionnement du vivant. Bien que rÃ©ductrice, cette approche permettra notamment dâ€™envisager les premiÃ¨res thÃ©ories concernant lâ€™intelligence artificielle basÃ©e sur le raisonnement humain.

Lâ€™engouement autour de la cybernÃ©tique sâ€™essouffle Ã  la moitiÃ© des annÃ©es 1960, mais son influence reste aujourdâ€™hui encore perceptible dans de nombreux domaines scientifiques tels que les sciences cognitives, lâ€™informatique et bien sÃ»r, les recherches en IA.

**Â« Les machines peuvent-elles penser ? Â»**

Câ€™est la question que pose le mathÃ©maticien britannique Alan Turing dans un cÃ©lÃ¨bre article publiÃ© en 1950. Pour y rÃ©pondre, il propose le Â« jeu de lâ€™imitation Â», Ã©galement connu sous le nom de Â« Test de Turing Â». Lâ€™expÃ©rience se rÃ©sume comme suit : Un Ãªtre humain (A) est mis en communication via un clavier et un Ã©cran, avec deux entitÃ©s quâ€™il ne voit pas et dont il ignore la nature ; dâ€™un cÃ´tÃ©, se trouve un ordinateur (B), de lâ€™autre, un humain (C). Si, au bout de 5 minutes de conversation, lâ€™Ãªtre humain (A) nâ€™est pas capable de savoir qui de (B) et (C) est lâ€™ordinateur, ce dernier passe le test.

Le jeu de lâ€™imitation est avant tout un exemple thÃ©orique. La puissance des machines des annÃ©es 1950 ne permet pas dâ€™envisager lâ€™assimilation des questions et encore moins la formulation de rÃ©ponses adaptÃ©es. Aujourdâ€™hui, les agents conversationnels ou chat bots sont ce qui se rapprochent le plus de lâ€™ordinateur du jeu de lâ€™imitation. Leurs performances actuelles demeurent relativement faibles et sont encore loin de crÃ©er la confusion pour les utilisateurs.

Au-delÃ  de la pertinence du jeu de lâ€™imitation, sa conceptualisation permet de comprendre comment Turing concevait la pensÃ©e. Pour lui, il sâ€™agit de capacitÃ©s cognitives, câ€™est-Ã -dire dâ€™un ensemble de facultÃ©s qui permettent dâ€™apprendre, dâ€™organiser et dâ€™utiliser les connaissances. En considÃ©rant que la pensÃ©e peut Ãªtre rÃ©duite Ã  un ensemble de facultÃ©s dÃ©finies (entre autres la perception, la mÃ©moire et le langage), il devient Ã©galement possible dâ€™envisager de les reproduire de maniÃ¨re artificielle. Câ€™est sur ce principe, inspirÃ© de la cybernÃ©tique, que se baseront les premiÃ¨res recherches dans le domaine, quelques annÃ©es plus tard. Cette approche trÃ¨s rationnelle de la pensÃ©e permet de placer lâ€™intelligence humaine et lâ€™intelligence artificielle au mÃªme niveau afin de les mettre en opposition. Le rapport de force entre lâ€™Ãªtre humain et la machine instaurÃ© par Turing exercera une influence certaine dans lâ€™histoire. Cette opposition servira de point de repÃ¨re pour Ã©valuer lâ€™efficacitÃ© de diffÃ©rents systÃ¨mes dâ€™IA face Ã  lâ€™intelligence humaine.

**CrÃ©ation dâ€™un domaine scientifique**

Le terme intelligence artificielle ou plutÃ´t artificial intelligence en anglais, apparait pour la premiÃ¨re fois en 1955 aux Ã‰tats-Unis. Quatre scientifiques formÃ©s en mathÃ©matiques et en neurologie organisent une confÃ©rence dâ€™Ã©tÃ© au Dartmouth College, afin de rÃ©flÃ©chir aux questions de programmation et de langage des ordinateurs, de rÃ©seaux de neurones, de puissance de calcul et dâ€™auto-apprentissage. Mises ensemble, ces disciplines forment un nouveau domaine appelÃ© "intelligence artificielle".
Dans leur [proposition de projet](http://jmc.stanford.edu/articles/dartmouth/dartmouth.pdf) les auteurs expliquent leur approche de la maniÃ¨re suivante :

*Â« Lâ€™Ã©tude devra se dÃ©rouler sur la base de la conjecture que chaque aspect de lâ€™apprentissage ou toute autre caractÃ©ristique de lâ€™intelligence peut, en principe, Ãªtre dÃ©crit avec une telle prÃ©cision quâ€™une machine peut Ãªtre conÃ§ue pour la simuler Â»*

Lâ€™un des buts motivant les premiÃ¨res recherches en IA est explicitement de reproduire lâ€™intelligence humaine. Comme Turing avant eux, les pionniers de lâ€™IA partent du principe que le fonctionnement du raisonnement humain est suffisamment compris pour Ãªtre modÃ©lisÃ©. 

Certes, cette approche permet dâ€™ouvrir la voie dans certains domaines bien prÃ©cis. Cependant, lâ€™intelligence humaine ne se limite pas Ã  un processus logique, mesurable et individuel contrairement aux idÃ©es des pionniers de lâ€™IA. Cette conception est en fait porteuse dâ€™un paradoxe : pour pouvoir modÃ©liser et reproduire artificiellement lâ€™intelligence, elle est rÃ©duite Ã  des fonctions dÃ©finies. Or, les notions dâ€™intelligence sociale, Ã©motionnelle ou crÃ©ative sont exclues du problÃ¨me. La notion du corps est Ã©galement totalement absente de ces considÃ©rations.

**Courants symbolique et connexionniste**

Trouver une dÃ©finition gÃ©nÃ©rale de lâ€™IA est un exercice difficile car il sâ€™agit en fait dâ€™un ensemble de technologies particuliÃ¨res. Historiquement, on diffÃ©rencie principalement deux approches.D'un cÃ´tÃ©, lâ€™**IA symbolique** qui vise Ã  reproduire le raisonnement humain sous la forme de rÃ¨gles statiques pour lâ€™intÃ©grer Ã  des machines. Câ€™est sur ce principe que reposent lâ€™ordinateur du jeu de lâ€™imitation et plus gÃ©nÃ©ralement les **systÃ¨mes experts**. De lâ€™autre, lâ€™**IA connexionniste** est un ensemble de techniques dâ€™apprentissage basÃ©es sur de grands volumes de donnÃ©es. Elle comprend lâ€™**apprentissage automatique** ou machine learning et lâ€™**apprentissage profond** ou deep learning. Cette derniÃ¨re utilise des modÃ¨les de **rÃ©seaux de neurones**, superposÃ©s en plusieurs couches pour Ã©tablir des rÃ¨gles complexes de maniÃ¨re autonome. 

**PrÃ©dire Ã  partir des donnÃ©es**

Aujourdâ€™hui, lâ€™IA fait principalement rÃ©fÃ©rence aux techniques dâ€™apprentissage automatique. Le but des systÃ¨mes intÃ©grant ces technologies est dâ€™exploiter de grands volumes de donnÃ©es afin dâ€™Ã©tablir des modÃ¨les statistiques qui serviront ensuite Ã  orienter des dÃ©cisions de maniÃ¨res automatiques. 

Mais le travail des ingÃ©nieurs demeure central tant dans le choix et la prÃ©paration des donnÃ©es exploitÃ©es que dans le dÃ©veloppement et lâ€™application des algorithmes. Les tÃ¢ches de collecte, de tri et de mise en forme des donnÃ©es se doivent dâ€™Ãªtre effectuÃ©es de maniÃ¨re rÃ©flexive, en prenant en compte les buts du traitement automatiques de lâ€™information. Le dÃ©veloppement ou le choix des algorithmes qui traiteront les donnÃ©es sont Ã©galement Ã  considÃ©rer. Finalement, le travail dâ€™interprÃ©tation des rÃ©sultats est nÃ©cessaire, puisque le systÃ¨me se limite Ã  Ã©laborer des modÃ¨les statistiques, basÃ©s sur des propriÃ©tÃ©s mathÃ©matiques.

<div align="left"; style="font-size:20px ;color:rgb(0, 0, 0); font-family:helvetica">
  <b>â™– Avec ou contre l'Ãªtre humain?</b>
</div>

La force de prÃ©diction des intelligences artificielles nâ€™a cessÃ© dâ€™augmenter depuis son Ã©mergence. En 1997, la victoire du superordinateur Deep Blue (IBM) face au grand maÃ®tre dâ€™Ã©checs Garry Kasporov marque un tournant dans lâ€™histoire opposant lâ€™humain Ã  la machine. 

Lors de sa victoire, Deep Blue calcule environ 200 millions de possibilitÃ©s par seconde ce qui correspond Ã  lâ€™anticipation de 12 coups. Kasparov est capable dâ€™anticiper au mieux les 10 prochains coups. Mais cet exploit a Ã©galement nÃ©cessitÃ© dâ€™importants moyens humains. Les ingÃ©nieurs dâ€™IBM ont travaillÃ© plus de 10 ans pour dÃ©velopper Â«Deep BlueÂ». Ce sont Ã©galement des donnÃ©es produites par de grands joueurs qui ont servi Ã  entrainer la machine.  

En 2015, lâ€™histoire de lâ€™IA est Ã  nouveau marquÃ©e par une victoire de la machine sur lâ€™Ãªtre humain. Le programme informatique AlphaGo (dÃ©veloppÃ©e par la sociÃ©tÃ© britannique Deep Mind, rachetÃ©e par Google en 2014) bat un joueur professionnel lors dâ€™une partie du traditionnel jeu de Go. Lâ€™exploit rÃ©side surtout dans le cheminement empruntÃ© pour parvenir Ã  cette victoire. Le jeu de Go est bien plus complexe que les Ã©checs et les possibilitÃ©s sont trop nombreuses pour Ãªtre listÃ©es et apprises Ã  une machine. Une combinaison dâ€™apprentissage supervisÃ© considÃ©rant des parties jouÃ©es par des humains et dâ€™apprentissage profond uniquement basÃ© sur lâ€™expÃ©rience de la machine va permettre Ã  AlphaGo de dÃ©duire les coups optimaux et de battre pour la premiÃ¨re fois de lâ€™histoire un joueur professionnel. La derniÃ¨re version du programme baptisÃ©e AlphaGo Zero est parvenue Ã  battre nâ€™importe quel joueur humain ainsi quâ€™AlphaGo lui-mÃªme, en apprenant uniquement de sa propre expÃ©rience. Le programme est ainsi devenu imbattable. 

Ces exemples montrent que les technologies de lâ€™IA peuvent sâ€™avÃ©rer plus performantes que lâ€™Ãªtre humain dans des situations prÃ©cises. Ces domaines de performance correspondent Ã  des environnements fermÃ©s, oÃ¹ le but est fixÃ© Ã  lâ€™avance. Câ€™est le cas du jeu dâ€™Ã©chec et du jeu de Go. La capacitÃ© dâ€™adaptation contextuelle des systÃ¨mes dâ€™IA constitue lâ€™un des dÃ©fis non rÃ©solu pour les chercheurs.  

Câ€™est Ã©galement grÃ¢ce au contexte du jeu que subsiste la logique dâ€™opposition entre le joueur et la machine, dans la continuitÃ© du Test de Turing. Mais cette logique Ã©lude tout le travail humain consacrÃ© au dÃ©veloppement des programmes et des algorithmes, sans lesquels lâ€™exploit ne peut pas avoir lieu. Des annÃ©es de dÃ©veloppement et de tests rÃ©alisÃ©s par des ingÃ©nieurs, associÃ©s Ã  des donnÃ©es issues de parties jouÃ©es par des Ãªtres humains sont nÃ©cessaires pour parvenir Ã  de telles performances. En prenant un pas de recul sur les performances de Deep Blue et AlphaGo, lâ€™opposition apparente entre lâ€™humain et la machine se transforme en un exploit collaboratif entre les ingÃ©nieurs dâ€™une part, mais Ã©galement avec la technologie et la puissance de calcul des ordinateurs dâ€™autre part.  

> **La SingularitÃ© technologique** 
<br>
La SingularitÃ© technologique correspond au moment hypothÃ©tique du dÃ©passement de lâ€™intelligence humaine par lâ€™intelligence artificielle. Plusieurs scientifiques dont Ray Kurzweil, Stephen Hawking et Elon Musk ont fait part de leurs inquiÃ©tudes quant aux dangers potentiels dâ€™une technologie qui deviendra tÃ´t ou tard, supÃ©rieure aux humains.
<br>
La thÃ©orie de la singularitÃ© est basÃ©e sur la loi de Moore qui illustre lâ€™Ã©volution exponentielle de la puissance de calcul des ordinateurs. En effet, depuis les premiers microprocesseurs des annÃ©es 1970, on observe que le nombre de transistors double environ tous les deux ans. Les dÃ©fenseurs de la singularitÃ© partent du principe que cette croissance exponentielle continuera jusquâ€™Ã  ce que les machines soient elles-mÃªmes capables de programmer dâ€™autres machines. 
<br>
Or, ces prÃ©dictions omettent plusieurs facteurs et il parait aujourdâ€™hui difficile de penser que la croissance technologique poursuive sa route vers lâ€™infini.  Les limites matÃ©rielles et Ã©nergÃ©tiques ne sont par exemple pas prises en compte. Les dÃ©tracteurs de la singularitÃ© considÃ¨rent que ces prÃ©dictions relÃ¨vent plus de la science-fiction que de faits scientifiques fiables. 
<br>
Pour aller plus loin: 
Jean-Gabriel Ganascia (2017), Le mythe de la SingularitÃ©. Faut-il craindre lâ€™intelligence artificielle. Ã‰dition du Seuil.
<div align="left"; style="font-size:20px ;color:rgb(0, 0, 0); font-family:helvetica">
  <b>ğŸ§¬ Terrains de prÃ©dilection</b>
</div>

<br>

Les possibilitÃ©s offertes par lâ€™IA et les grands volumes de donnÃ©es disponibles font miroiter des perspectives inÃ©dites en termes de vitesse, de puissance et de quantitÃ© dâ€™information pouvant Ãªtre traitÃ©e. Depuis la fin des annÃ©es 2010, les techniques dâ€™apprentissage automatique basÃ©es sur des rÃ©seaux de neurones ont rÃ©volutionnÃ© des domaines tels que la traduction automatique, le traitement dâ€™images et de la recherche en bio-informatique. 

Actif depuis 2017, le traducteur automatique DeepL a dÃ©passÃ© ses concurrents Google Translate, Microsoft Traduction et Facebook. En apprenant de textes existants indexÃ©es sur la base de donnÃ©es du site Linguee, DeepL offre un service de traduction efficace pour plus de 26 langues. 

Les technologies de traitement automatique de lâ€™image et du son sont Ã©galement performantes, si elles sont entraÃ®nÃ©es avec une quantitÃ© suffisante de donnÃ©es. Dans le domaine de lâ€™audio-visuel, la technique du deepfake sâ€™est rependue depuis 2017. Elle permet de reconstituer le visage dâ€™une personne de maniÃ¨re ultra rÃ©aliste, de la mettre en scÃ¨ne et de lui faire tenir des propos inventÃ©s. Cette technique est particuliÃ¨rement efficace avec des personnalitÃ©s publiques (acteur-trice-s, politicien-nes, etc.) dont les images sont nombreuses et facilement accessibles sur Internet. UtilisÃ©e correctement, la technique du deepfake est difficile Ã  desceller. Les risques relatifs Ã  cette technologie sont les possibilitÃ©s de nuire Ã  un individu en utilisant son image dans un contexte inappropriÃ©. Les possibilitÃ©s de manipulation des opinions politiques ont aussi Ã©tÃ© pointÃ©e du doigt, en France et aux Ã‰tats-Unis.

Finalement, la sociÃ©tÃ© DeepMind sâ€™est inspirÃ©e des mÃ©thodes dâ€™apprentissage profond utilisÃ©es par AlphaGo pour dÃ©velopper AlphaFold.
En 2020, le systÃ¨me a permis de modÃ©liser des protÃ©ines encore mÃ©connues en un temps record. Ces nouvelles approches contribuent par exemple Ã  lâ€™accÃ©lÃ©ration du dÃ©veloppement de certains vaccins. 

**(...)**


<div align="left"; style="font-size:20px ;color:rgb(0, 0, 0); font-family:helvetica">
  <b>ğŸ›  Le travail au dÃ©fi de l'automatisation</b>
</div>

<br>
La logique de lâ€™opposition entre lâ€™Ãªtre humain et la machine, souvent thÃ©matisÃ© en science-fiction et reprise dans la prÃ©sentation des victoires de Deep Blue et AlphaGo, entretient la crainte du remplacement des travailleurs et travailleuses humains par des systÃ¨mes automatisÃ©s. En 2013, une Ã©tude menÃ©e par des chercheurs de lâ€™UniversitÃ© dâ€™Oxford conclut que 47% des emplois ont une forte probabilitÃ© de disparaÃ®tre compte tenu des avancÃ©es dans le domaine de lâ€™apprentissage automatique. Des erreurs mÃ©thodologiques sont rapidement identifiÃ©es et discrÃ©dites les rÃ©sultats de cette recherche. Le sociologue Antonio Casilli (EHESS) souligne que les auteurs de lâ€™Ã©tude dâ€™Oxford ne prennent pas en compte les rÃ©sistances sociales souvent engendrÃ©es par la suppression de postes de travail.

Dans un [article scientifique](https://www.aeaweb.org/articles?id=10.1257/jep.29.3.3) publiÃ© en 2015, lâ€™Ã©conomiste David H. Autor (MIT) dÃ©montre que les peurs liÃ©es au remplacement du travail de lâ€™Ãªtre humain par la machine ne sont ni nouvelles, ni fondÃ©es. Au dÃ©but du XIX<sup>e</sup> siÃ¨cle, en Grande Bretagne, des travailleurs de lâ€™industrie du textile dÃ©truisent des machines quâ€™ils accusent de provoquer le chÃ´mage. Si lâ€™automatisation de certaines tÃ¢ches a bien eu lieu au cours du XX<sup>e</sup> siÃ¨cle et continue aujourdâ€™hui encore, [lâ€™Ã©volution des taux de chÃ´mage de diffÃ©rents pays](https://data.oecd.org/unemp/unemployment-rate.htm) ne reflÃ¨tent pas une baisse drastique de lâ€™emploi.

**Polarisation, pas remplacement**

Dans son livre En attendant les robots (Seuil, 2019) Antionio Casilli dÃ©construit la croyance du remplacement du travail de lâ€™Ãªtre humain par les machines et les IA. Selon lâ€™auteur, les emplois ne disparaissent pas, mais se transforment. Avec lâ€™arrivÃ©e des grands noms du numÃ©rique, le phÃ©nomÃ¨ne de polarisation du travail semble sâ€™amplifier. Dâ€™un cÃ´tÃ©, on constate une forte demande pour les mÃ©tiers hautement spÃ©cialisÃ©s, de lâ€™autre, un besoin croissant de main dâ€™Å“uvre peu qualifiÃ©e pour effectuer des tÃ¢ches rÃ©pÃ©titives et standardisÃ©es, essentielles au bon fonctionnement des systÃ¨mes automatisÃ©s. 

Ce travail humain, peu qualifiÃ© mais indispensable Ã  lâ€™entraÃ®nement des IA, entre dans la catÃ©gorie du *digital labour*. Les entreprises ayant recours Ã  ce type de  main dâ€™Å“uvre font gÃ©nÃ©ralement appel Ã  des services externalisÃ©s et le travail est divisÃ© en micro-tÃ¢ches (cliquer sur des images, retranscrire un texte, etc.). Les rÃ©munÃ©rations ne dÃ©passent que rarement les quelques centimes par micro-tÃ¢ches effectuÃ©es. Cette nouvelle catÃ©gorie dâ€™emplois peu qualifiÃ©s, rÃ©munÃ©rÃ©s Ã  la tÃ¢che et externalisÃ©, dÃ©valorise le travail humain au profit des grandes entreprises. 


<div align="left"; style="font-size:20px ;color:rgb(0, 0, 0); font-family:helvetica">
  <b>ğŸ“± L'IA et nos pratiques numÃ©riques</b>
</div>

<br>
Les pratiques en ligne sont orientÃ©es par des algorithmes qui collectent, agencent et analyses les traces numÃ©riques des utilisateurs de maniÃ¨re automatisÃ©e. Ainsi, les contenus, les suggestions et les publicitÃ©s qui apparaissent sur leur Ã©cran sont dÃ©terminÃ©s Ã  partir de leurs donnÃ©es respectives. Voici quelques exemples de domaines oÃ¹ une forme dâ€™IA influence les contenus consommÃ©s : 

* E-commerce (Amazon, Galaxus, Zalando)
* Moteurs de recherche (Google Suggest)
* Plateformes de streaming vidÃ©o (YouTube, Netflix)
* Plateformes de streaming audio (Spotify, Apple Music, Deezer)
* MÃ©dias sociaux (Facebook, Instagram, Twitter, TikTok,  Twitch)

Proposer du contenu Â«sur mesureÂ» vise Ã  amÃ©liorer lâ€™expÃ©rience des utilisateurs  et des utilisatrices afin de prolonger le temps passÃ© sur un site ou une application. NÃ©anmoins, lâ€™automatisation de certaines tÃ¢ches est problÃ©matique pour diffÃ©rentes raisons. 

**L'effet bulle de filtre**

Lâ€™un des phÃ©nomÃ¨ne engendrÃ© par la suggestion automatique de contenu individualisÃ© est lâ€™effet bulle de filtre. 

Ã‰tant donnÃ© que les prÃ©dictions se font Ã  partir des traces existantes, les contenus et publicitÃ©s suggÃ©rÃ©s par algorithmes vont toujours dans le sens de lâ€™utilisateur ou de lâ€™utilisatrice. Lâ€™effet bulle de filtre est particuliÃ¨rement fort sur les fils dâ€™actualitÃ© des rÃ©seaux sociaux tels que Instagram, Tik Tok ou YouTube oÃ¹ les informations sur les profils sont nombreuses (genre, Ã¢ge, localisation, etc.). La possibilitÃ© dâ€™interagir avec les contenus, via les fonctions Â« jâ€™aime Â» ou Â« ce contenu ne m'interesse pas Â»  renforce le profilage des comptes et augmente les probabilitÃ©s de voir les mÃªmes types de contenus apparaÃ®tre plus tard. 

Les rÃ©sultats des requÃªtes sur le moteur de recherche de Google varient Ã©galement en fonction des donnÃ©es connues sur lâ€™utilisateur ou lâ€™utilisatrice. MÃªme sâ€™il / elle nâ€™est pas connectÃ©-e Ã  un compte, Google prend en considÃ©ration la gÃ©olocalisation, le type dâ€™appareil ou encore le navigateur utilisÃ© lors de lâ€™affichage des rÃ©sultats. Deux individus faisant la mÃªme recherche auront ainsi des propositions de contenus diffÃ©rentes. 

La critique principale de lâ€™effet bulle de filtre est quâ€™il maintient les individus dans leur zone de confort idÃ©ologique et ne permet de les confronter Ã  dâ€™autres visions du monde. [Pour le sociologue Dominique Cardon](https://www.lemonde.fr/pixels/article/2016/11/14/facebook-faiseur-de-rois-de-l-election-americaine_5030959_4408996.html), ce ne sont pas les algorithmes qui sont Ã  l'origine du phÃ©nomÃ¨ne mais plutÃ´t les choix d'affiliation (ami-e-s, pages suivies, etc.) de chaque utilisateur et utilisatrice. La suggestion automatique de contenu amplifie ainsi un effet prÃ©existant au numÃ©rique. Car mÃªme avant l'apparition d'internet, les individus ont toujours eu pour habitude de chercher Ã  confirmer leurs opinions plutÃ´t que de les confronter et les remettre en question. L'effet bulle de filtre est donc bien rÃ©el mais il ne s'agit pas d'une nouveau phÃ©nomÃ¨ne propre Ã  l'IA.

**Les biais**

Dans le domaine des statistiques, le biais correspond Ã  une erreur mÃ©thodologique qui engendre de faux rÃ©sultats. Il peut Ãªtre causÃ© par de la sÃ©lection dâ€™un Ã©chantillon non-reprÃ©sentatif ou par la maniÃ¨re de collecter les donnÃ©es. Les algorithmes des IA, dont les choix sont dÃ©terminÃ©s par des calculs exploitant diffÃ©rents types de donnÃ©es, sont Ã©galement Ã  lâ€™origine de nombreux biais.

Au dÃ©but du mois de septembre 2021, une ancienne employÃ©e de Facebook [dÃ©nonce un biais raciste](https://www.24heures.ch/facebook-a-confondu-des-personnes-noires-avec-des-singes-677330452425) dans lâ€™algorithme de suggestion de la plateforme. Au bas dâ€™une vidÃ©o dans laquelle figure des personnes noires, une banniÃ¨re demande Ã  lâ€™utilisateur sâ€™il ou elle souhaite continuer Ã  Â« voir des vidÃ©os sur des primates Â». Ã€ la suite de cet Ã©pisode, Facebook admet que cette erreur est inacceptable sâ€™excuse. Mais comment un tel scÃ©nario est-il possible? Pour le savoir, il faut comprendre le fonctionnement des techniques de reconnaissance automatique dâ€™images.

Lorsquâ€™un programme est dÃ©veloppÃ© pour reconnaÃ®tre des images, un volume important de donnÃ©es (dans ce cas, dâ€™images) est nÃ©cessaire pour apprendre Ã  reconnaitre les diffÃ©rentes formes qui la composent. Des techniques dâ€™apprentissage automatique supervisÃ© permettent par exemple de faire la diffÃ©rence entre ce qui est un visage et ce qui ne lâ€™est pas. Dans le cas de lâ€™algorithme de Facebook, la base de donnÃ©es utilisÃ©es ne contenait vraisemblablement pas assez dâ€™exemples reprÃ©sentant des personnes de couleurs.

Lâ€™enjeu des biais se situe au niveaux de la qualitÃ© des bases de donnÃ©es disponibles pour entrainer les algorithmes. Si les donnÃ©es ne sont pas reprÃ©sentatives de la diversitÃ© des individus, des biais seront inÃ©vitablement reproduits. Lâ€™utilisation de systÃ¨mes dâ€™apprentissage automatique dans les processus de prise de dÃ©cision nâ€™Ã©tant pas limitÃ©e aux pratiques en ligne, les risques de voir ces biais se reproduire sont rÃ©els. Dans son ouvrage *Weapons of Math Destruction* (2016, Crown Books), la mathÃ©maticienne Cathy Oâ€™Neil met en garde contre lâ€™utilisation des big data et des algorithmes dans le domaine des assurances, du recrutement et des forces de lâ€™ordre. Elle explique que la dÃ©lÃ©gation dâ€™importantes prises de dÃ©cision Ã  des programmes automatiques est dangereuse car elle renforce les inÃ©galitÃ©s existantes dans la sociÃ©tÃ©. 

Pour contrer cette tendance de reproduction numÃ©rique des biais, lâ€™ingÃ©nieure Joy Buolamwini  (MIT) a crÃ©Ã© la plateforme *Algorithmic Justice League*. Elle propose de rendre le domaine de lâ€™IA plus inclusif, en sâ€™assurant notamment que les spÃ©cialistes reprÃ©sentent la diversitÃ© de la sociÃ©tÃ©. Augmenter la part de femmes et de personnes non-blanches dans le processus de dÃ©veloppement et d'entraÃ®nement des IA permettrait d'Ã©viter de grossiÃ¨res erreurs de discrimination.




<div align="left"; style="font-size:20px ;color:rgb(0, 0, 0); font-family:helvetica">
  <b>ğŸ‘©ğŸ»â€âš–ï¸ RÃ©guler</b>
</div>
<br>
Ã€ la suite des diverses controverses engendrÃ©es par les biais racistes des IA, certaines grandes entreprises comme Google, Microsoft ou IBM ont mis en place des comitÃ©s dâ€™Ã©thique. Plusieurs projets en cours ont ainsi Ã©tÃ© suspendus ou abandonnÃ©s en raison du risque de perpÃ©tuer des pratiques discriminatoires. Il sâ€™agit dans ce cas dâ€™une forme de gouvernance interne aux entreprises qui n'est pas contraignante. 

Une autre maniÃ¨re de rÃ©guler lâ€™IA est de lÃ©gifÃ©rer sur ses usages. Aux [Ã‰tats-Unis](https://www.ncsl.org/research/telecommunications-and-information-technology/2020-legislation-related-to-artificial-intelligence.aspx), leader mondial dans le domaine, seuls quatre Ã©tats avaient adoptÃ© une forme de regulation relative Ã  l'IA en 2021. En Europe, la Commission EuropÃ©enne a proposÃ© en avril 2021 Â« [un ensemble dâ€™actions visant Ã  stimuler lâ€™excellence dans le domaine de lâ€™IA, ainsi que des rÃ¨gles destinÃ©es Ã  garantir la fiabilitÃ© de cette technologie](https://ec.europa.eu/france/news/20210421/nouvelles_regles_europeennes_intelligence_artificielle_fr) Â». Afin dâ€™estimer les risques que pourraient reprÃ©senter lâ€™IA pour les citoyens et citoyennes, la CE propose un classement qui dÃ©termine le niveau de rÃ©gulation nÃ©cessaire pour chaque domaine. La catÃ©gorie Â« haut risque Â» comprend par exemple les logiciels de recrutement ou les prises de dÃ©cision automatisÃ©es dans lâ€™attribution dâ€™un crÃ©dit, situations oÃ¹ les biais sont souvent prÃ©sents. 

La situation est encore diffÃ©rente en Chine, oÃ¹ le gouvernement a publiÃ© un plan dans le but de devenir le leader mondial dans le domaine de l'IA d'ici 2030. Pour atteindre cet objectif, l'Etat n'entend  pas rÃ©guler l'IA mais encourage et soutient les start-ups et entrerpises impliquÃ©es dans le domaine. 

Lâ€™Europe apparait donc comme le seul endroit oÃ¹ des perspectives concrÃ¨tes de rÃ©glementation du numÃ©rique et plus prÃ©cisÃ©ment de lâ€™IA et des ses usages sont envisagÃ©es. Il faudra nÃ©anmoins attendre encore quelques annÃ©es avant lâ€™entrÃ©e en vigueur de lâ€™ensemble des lois proposÃ© par la CE. 

Ces diffÃ©rentes approches quant Ã  la rÃ©gulation de lâ€™IA traduisent lâ€™ambiguÃ¯tÃ© des technologies quâ€™elle englobe. Lâ€™Europe considÃ¨re leur utilisation comme potentiellement dangereuse pour la sociÃ©tÃ© et y voit donc un besoin de rÃ©gulation par lâ€™Ã©tat. La maÃ®trise de lâ€™IA constitue un outil de mesure de la puissance nationale pour la Chine, ce qui ne favorise aucunement sa rÃ©gulation. 

### Ressources

* [Le sous-chapitre](https://www.boullier.bzh/livres/boullier-dominique-sociologie-du-numerique/) "Science-fiction et mythologie du numÃ©rique" du livre *Sociologie du numÃ©rique* (2016) de Dominique Boullier pour une discussion concernant les liens entre la science-fiction et le numÃ©rique. (303-306)

* [Le sous-chapitre](https://www.pressesdesciencespo.fr/fr/book/?gcoi=27246100540390) "L'intelligence artificielle" dans le livre Culture numÃ©rique de Dominique Cardon pour une brÃ¨ve prÃ©sentation de l'IA. (385-398)

* [Le livre](https://www.seuil.com/ouvrage/le-mythe-de-la-singularite-jean-gabriel-ganascia/9782021309997) *Le mythe de la singularitÃ©* (2017) de Jean-Gabriel Ganascia 

* [Le documentaire](https://www.youtube.com/watch?v=WXuK6gekU1Y&t=3466s) AlphaGo - The Movie (2017) de Greg Kohs pour comprendre la victoire d'AlphaGo sur Lee Sedol

* [Un reportage](https://www.rts.ch/info/sciences-tech/technologies/11684864-lalgorithme-de-facebook-est-sexiste-pour-les-offres-demploi.html) de l'Ã©mission Mise au point de la RTS pour un exemple de biais engendrÃ© par un algorithme de Facebook. 

### Glossaire

* IA symbolique
* IA connexionniste
* SystÃ¨me expert
* Apprentissage automatique ou *machine learning*
* Apprentissage profond ou *deep learning*
* RÃ©seaux de neurones
* *Chatbot*


<br>

## Pistes pÃ©dagogiques 

<br>

<div align="left"; style="font-size:20px ;color:rgb(0, 0, 0); font-family:helvetica">
  <b>Usages quotidiens</b>
</div>


1. IA ou pas? | DÃ©branchÃ©

Objectif : Ãªtre capable d'identifier les situations dans lesquelle l'IA influence les contenus consultÃ©s. 

MatÃ©riel:
* Captures d'Ã©cran Ã  projeter Ã  la classe 

2. Jeu de l'imitation | BranchÃ©

Objectif : Prendre conscience des forces et des limites d'un assistant vocal

MatÃ©riel: 
* Un assistant vocal de type Siri
* Une liste de [questions](https://www.aiunplugged.org/activity5-german.pdf) (En allemand pour l'instant)


Par groupe de 3 trois, les Ã©lÃ¨ves posent tour Ã  tour les questions de la liste Ã  un assistant vocal et notent les rÃ©ponses.

<div align="left"; style="font-size:20px ;color:rgb(0, 0, 0); font-family:helvetica">
  <b>Gouvernance</b>
  </div>

  1. DÃ©bat
  
  Un jeu de rÃ´le par groupe. 
  Chaque groupe reprÃ©sente un acteur social de type citoyen / gouvernement / plateforme / scientifique... et 